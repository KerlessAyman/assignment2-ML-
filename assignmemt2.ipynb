{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Balancing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   28.7967   16.0021    2.6449    0.3918    0.1982   27.7004   22.0110   \n",
      "1   31.6036   11.7235    2.5185    0.5303    0.3773   26.2722   23.8238   \n",
      "2  162.0520  136.0310    4.0612    0.0374    0.0187  116.7410  -64.8580   \n",
      "3   23.8172    9.5728    2.3385    0.6147    0.3922   27.2107   -6.4633   \n",
      "4   75.1362   30.9205    3.1611    0.3168    0.1832   -5.5277   28.5525   \n",
      "\n",
      "   feature8  feature9  feature10 class  \n",
      "0   -8.2027   40.0920    81.8828     g  \n",
      "1   -9.9574    6.3609   205.2610     g  \n",
      "2  -45.2160   76.9600   256.7880     g  \n",
      "3   -7.1513   10.4490   116.7370     g  \n",
      "4   21.8393    4.6480   356.4620     g  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "columns = [\"feature1\", \"feature2\", \"feature3\", \"feature4\", \"feature5\", \"feature6\",\n",
    "           \"feature7\", \"feature8\", \"feature9\", \"feature10\", \"class\"]\n",
    "data=pd.read_csv(\"magic04.data\",names=columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    6688\n",
      "0    6688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate classes\n",
    "gamma_data = data[data[\"class\"] == \"g\"]\n",
    "hadron_data = data[data[\"class\"] == \"h\"]\n",
    "# Match the size of the smaller class (hadron: 6688)\n",
    "gamma_sampled = gamma_data.sample(n=len(hadron_data), random_state=42)\n",
    "# Concatenate balanced data\n",
    "data_balanced=pd.concat([gamma_sampled, hadron_data], axis=0)\n",
    "# Shuffle the rows\n",
    "data_balanced = shuffle(data_balanced, random_state=42).reset_index(drop=True)\n",
    "# Encode class label (gamma: 1, hadron: 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data_balanced[\"class\"] = LabelEncoder().fit_transform(data_balanced[\"class\"])\n",
    "\n",
    "print(data_balanced[\"class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (9363, 10), Testing set: (4013, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Features (X) and target (y)\n",
    "x=data_balanced.drop(\"class\", axis=1)\n",
    "y=data_balanced[\"class\"]\n",
    "\n",
    "# Split the dataset (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test =train_test_split(x,y, test_size=0.3,random_state=42,stratify=y)\n",
    "\n",
    "# Verify the shape of the split data\n",
    "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (a) Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "df_model=DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "df_model.fit(X_train,y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "dt_predictions = df_model.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.8243\n",
      "Best n_estimators for AdaBoost: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Initialize the AdaBoost Classifier\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Set up the parameter grid for n_estimators\n",
    "param_grid_ada = {'n_estimators': [50, 100, 150, 200]}\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search_ada = GridSearchCV(ada_model, param_grid_ada, cv=5, scoring='accuracy')\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "# Best model and performance\n",
    "best_ada_model = grid_search_ada.best_estimator_\n",
    "ada_predictions = best_ada_model.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test, ada_predictions)\n",
    "print(f\"AdaBoost Accuracy: {ada_accuracy:.4f}\")\n",
    "print(f\"Best n_estimators for AdaBoost: {grid_search_ada.best_params_['n_estimators']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Random Forests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8634\n",
      "Best n_estimators for Random Forest: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the parameter grid for n_estimators\n",
    "param_grid_rf = {'n_estimators': [50, 100, 150, 200]}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best model and performance\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Best n_estimators for Random Forest: {grid_search_rf.best_params_['n_estimators']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Na¨ıve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Initialize the Naive Bayes Classifier\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n",
      "\n",
      "Decision Tree Accuracy: 0.7982\n",
      "AdaBoost Accuracy: 0.8243\n",
      "Random Forest Accuracy: 0.8634\n",
      "Naive Bayes Accuracy: 0.6566\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      2007\n",
      "           1       0.80      0.80      0.80      2006\n",
      "\n",
      "    accuracy                           0.80      4013\n",
      "   macro avg       0.80      0.80      0.80      4013\n",
      "weighted avg       0.80      0.80      0.80      4013\n",
      "\n",
      "\n",
      "AdaBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      2007\n",
      "           1       0.83      0.82      0.82      2006\n",
      "\n",
      "    accuracy                           0.82      4013\n",
      "   macro avg       0.82      0.82      0.82      4013\n",
      "weighted avg       0.82      0.82      0.82      4013\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      2007\n",
      "           1       0.89      0.83      0.86      2006\n",
      "\n",
      "    accuracy                           0.86      4013\n",
      "   macro avg       0.87      0.86      0.86      4013\n",
      "weighted avg       0.87      0.86      0.86      4013\n",
      "\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.90      0.72      2007\n",
      "           1       0.80      0.41      0.55      2006\n",
      "\n",
      "    accuracy                           0.66      4013\n",
      "   macro avg       0.70      0.66      0.64      4013\n",
      "weighted avg       0.70      0.66      0.64      4013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Model Comparison:\\n\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"AdaBoost Accuracy: {ada_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n",
    "\n",
    "# Optionally, print detailed classification reports for each model\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, dt_predictions))\n",
    "print(\"\\nAdaBoost Classification Report:\\n\", classification_report(y_test, ada_predictions))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "print(\"\\nNaive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a- Decision Tree Using cross val. Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[New] Tuned Decision Tree Accuracy: 0.7967\n",
      "[New] Best DT Params: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV  \n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [5, 15, 25, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), \n",
    "                       dt_param_grid, cv=5, scoring='accuracy')\n",
    "dt_tuned.fit(X_train, y_train)\n",
    "dt_tuned_pred = dt_tuned.predict(X_test)\n",
    "dt_tuned_acc = accuracy_score(y_test, dt_tuned_pred)\n",
    "\n",
    "print(f\"[New] Tuned Decision Tree Accuracy: {dt_tuned_acc:.4f}\")\n",
    "print(f\"[New] Best DT Params: {dt_tuned.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b- Naive Bayes - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[New] Tuned Naive Bayes Accuracy: 0.6628\n",
      "[New] Best NB Params: {'var_smoothing': 0.0004037017258596554}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nb_param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -12, num=100)\n",
    "}\n",
    "\n",
    "nb_tuned = GridSearchCV(\n",
    "    GaussianNB(),\n",
    "    nb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "nb_tuned.fit(X_train, y_train)\n",
    "print(f\"[New] Tuned Naive Bayes Accuracy: {accuracy_score(y_test, nb_tuned.predict(X_test)):.4f}\")\n",
    "print(f\"[New] Best NB Params: {nb_tuned.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c- AdaBoost - Expanded Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdal\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[New] Extended AdaBoost Accuracy: 0.8243\n",
      "[New] Best AdaBoost Params: {'learning_rate': 1.0, 'n_estimators': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_param_grid_ext = {\n",
    "    'n_estimators': [200, 300],  # Extends original [50, 100, 150, 200]\n",
    "    'learning_rate': [0.01, 0.1, 1.0]  # New parameter\n",
    "}\n",
    "\n",
    "ada_tuned_ext = GridSearchCV(\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    ada_param_grid_ext,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "ada_tuned_ext.fit(X_train, y_train)\n",
    "print(f\"[New] Extended AdaBoost Accuracy: {accuracy_score(y_test, ada_tuned_ext.predict(X_test)):.4f}\")\n",
    "print(f\"[New] Best AdaBoost Params: {ada_tuned_ext.best_params_}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d - Random Forest - Expanded Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[New] Extended Random Forest Accuracy: 0.8580\n",
      "[New] Best RF Params: {'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid_ext = {\n",
    "    'n_estimators': [200, 300],  # Extends original [50, 100, 150, 200]\n",
    "    'max_depth': [15, 30, None],  # New values\n",
    "    'max_features': ['sqrt', 'log2']  # New parameter\n",
    "}\n",
    "\n",
    "rf_tuned_ext = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid_ext,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "rf_tuned_ext.fit(X_train, y_train)\n",
    "print(f\"[New] Extended Random Forest Accuracy: {accuracy_score(y_test, rf_tuned_ext.predict(X_test)):.4f}\")\n",
    "print(f\"[New] Best RF Params: {rf_tuned_ext.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
